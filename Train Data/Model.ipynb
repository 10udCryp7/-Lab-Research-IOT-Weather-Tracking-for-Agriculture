{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ewtpy\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_day.csv')\n",
    "df2 = pd.read_csv('data_2018-08-05_2021-04-30.csv')\n",
    "df3 = pd.read_csv('data_2018-05-05_2018-08-04.csv')\n",
    "df4 = pd.read_csv('data_2015-08-09_2018-05-04.csv')\n",
    "df5 = pd.read_csv('data_2013-02-12_2015-08-08.csv')\n",
    "df = pd.concat([df5, df4, df3, df2, df1])\n",
    "print(df.to_string())\n",
    "data = df.to_numpy()\n",
    "temp = df['temp'].to_numpy()\n",
    "temp_max = df['tempmax'].to_numpy()\n",
    "temp_min = df['tempmin'].to_numpy()\n",
    "\n",
    "dew = df['dew'].to_numpy()\n",
    "humidity = df['humidity'].to_numpy()\n",
    "\n",
    "\n",
    "precipitation = df['precip'].to_numpy()\n",
    "precipcover = df['precipcover'].to_numpy()\n",
    "precipprob = df['precipprob'].to_numpy()\n",
    "\n",
    "windspeed = df['windspeed'].to_numpy()\n",
    "winddir = df['winddir'].to_numpy()\n",
    "\n",
    "cloudcover = df['cloudcover'].to_numpy()\n",
    "solar_radiation = df['solarradiation'].to_numpy()\n",
    "solarenergy = df['solarenergy'].to_numpy()\n",
    "uvindex = df['uvindex'].to_numpy()\n",
    "moonphase = df['moonphase'].to_numpy()\n",
    "\n",
    "training_set = np.array([humidity, temp, precipitation, precipprob, windspeed, solar_radiation])\n",
    "plt.plot(humidity)\n",
    "\n",
    "NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_set_tp = training_set.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(data, input_size, output_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.window(input_size + output_size, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(input_size + output_size))\n",
    "    X = dataset.map(lambda window: (window[:-output_size]))\n",
    "    y = dataset.map(lambda window: (window[-output_size:]))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf,y_tf = window_data(training_set_tp, 200, 1)\n",
    "X = np.array([x.numpy() for x in X_tf]).transpose(0,2,1)\n",
    "y = np.array([y.numpy() for y in y_tf]).transpose(0,2,1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(6,200,)),\n",
    "        tf.keras.layers.Dense(units = 25, activation = \"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.005)),\n",
    "        tf.keras.layers.Dense(units = 15, activation = \"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.005)),\n",
    "        tf.keras.layers.Dense(units = 10, activation = \"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.005)),\n",
    "        tf.keras.layers.Dense(units = 10, activation = \"linear\")\n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"mlpnn_model\" \n",
    ") \n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    ")\n",
    "print(X_train.shape)\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist_mlpnn = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=1000,  \n",
    "    # callbacks = [callback] \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential(\n",
    "#     [\n",
    "#         tf.keras.Input(shape=(5,)),\n",
    "#         tf.keras.layers.LSTM(units = 32),\n",
    "#     ], name = \"lstm_model\" \n",
    "# ) \n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "# )\n",
    "# if (NUM != 0):\n",
    "#     X_train = X_train[:-NUM]\n",
    "# else:\n",
    "#     X_train = X_train[:]\n",
    "# print(X_train.shape)\n",
    "# hist_mlpnn = model.fit(\n",
    "#     X_train,y_train,\n",
    "#     epochs=500,  \n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential(\n",
    "#     [\n",
    "#         tf.keras.Input(shape=(5,)),\n",
    "#         tf.keras.layers.Dense(units = 2000, activation = \"relu\",kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "#     bias_initializer=initializers.Zeros()),\n",
    "#         tf.keras.layers.Dense(units = 1, activation = \"linear\")\n",
    "#         ### END CODE HERE ### \n",
    "#     ], name = \"elm_model\" \n",
    "# ) \n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "# )\n",
    "# # callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "# if (NUM != 0):\n",
    "#     X_train = X_train[:-NUM]\n",
    "# else:\n",
    "#     X_train = X_train[:]\n",
    "# hist_elm = model.fit(\n",
    "#     X_train,y_train,\n",
    "#     epochs=1000,   \n",
    "#     # callbacks = [callback]\n",
    "# ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_predict = model.predict(X_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(yt_predict.shape)\n",
    "print(y_train.shape)\n",
    "feature = 0\n",
    "for i in range(1):\n",
    "    print(f\"TRAIN {i+1}\")\n",
    "    print(f\"R: {np.corrcoef(yt_predict[:,feature,i],y_train[:,feature,i])}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_train[:,feature,i],yt_predict[:,feature,i])**(1/2)}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_train[:,feature,i],yt_predict[:,feature,i])}\")\n",
    "for i in range(1):\n",
    "    print(f\"TRAIN {i+1}\")\n",
    "    print(f\"R: {np.corrcoef(y_predict[:,feature,i],y_test[:,feature,i])}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test[:,feature,i],y_predict[:,feature,i])**(1/2)}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test[:,feature,i],y_predict[:,feature,i])}\")\n",
    "plt.scatter(y_test[:,feature,0],y_predict[:,feature,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_predict = model.predict(X_train)\n",
    "y_predict = model.predict(X_test)\n",
    "plt.scatter(yt_predict[:,0],y_train[:,0])\n",
    "plt.scatter(y_predict[:,0],y_test[:,0])\n",
    "for i in range(len(y_predict) - NUM):\n",
    "    print(f\"predict: {y_predict[i,0]}, test: {y_test[i, 0]}\")\n",
    "\n",
    "print(\"TRAIN DETAIL\")\n",
    "print(f\"R: {np.corrcoef(yt_predict[:,0],y_train[:,0])}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_train[:,0],yt_predict[:,0])**(1/2)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_train[:,0],yt_predict[:,0])}\")\n",
    "# print(f\"SCORE: {accuracy_score(y_train[:,0],yt_predict[:,0])}\")\n",
    "mt, bt = np.polyfit(yt_predict[:,0],y_train[:,0], 1)\n",
    "plt.plot(yt_predict[:,0], mt*yt_predict[:,0]+bt, color = \"yellow\")\n",
    "#add linear regression line to scatterplot \n",
    "print(\"TEST DETAIL\")\n",
    "print(f\"R: {np.corrcoef(y_predict[:,0],y_test[:,0])}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test[:,0],y_predict[:,0])**(1/2)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test[:,0],y_predict[:,0])}\")\n",
    "# print(f\"SCORE: {accuracy_score(y_test[:,0],y_predict[:,0])}\")\n",
    "m, b = np.polyfit(y_predict[:,0],y_test[:,0], 1)\n",
    "plt.plot(y_predict[:,0], m*y_predict[:,0]+b, color = \"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'][200:500])\n",
    "# print(history.history[\"loss\"][400:500])\n",
    "plt.plot(hist_mlpnn.history['loss'][500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_predict, label = \"predict\")\n",
    "plt.plot(y_test)\n",
    "plt.plot(abs(y_predict - y_test))\n",
    "plt.legend(['predict', 'test', 'loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
